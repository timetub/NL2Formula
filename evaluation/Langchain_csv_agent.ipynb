{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxLWAbONc3ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os,read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from langchain.agents import create_csv_agent\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents.agent_types import AgentType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import importlib,utils,json,os\n",
        "from utils import *\n",
        "os.environ['OPENAI_API_KEY'] = read.read_json(os.path.join('configuration.json'))['OpenAI_api_key']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "read.read_json(os.path.join('configuration.json'))['OpenAI_api_key']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt_eval=utils.read_json(\"gpt_eval_3000.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt_eval[1].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def list_to_csv(data, file_path):\n",
        "    with open(file_path, 'w', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerows(data)\n",
        "\n",
        "def list_to_df(data,):\n",
        "    processed_data = [row[1:] for row in data[1:]]\n",
        "    df = pd.DataFrame(processed_data)\n",
        "    new_header = df.iloc[0] #grab the first row for the header\n",
        "    df = df[1:] #take the data less the header row\n",
        "    df.columns = new_header #set the header row as the df header\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# file_path = 'output_agent.csv'\n",
        "# Pass a query to the data\n",
        "for i,item in enumerate(gpt_eval[:1000]):\n",
        "    if \"LC_agent_res\" not in item.keys():\n",
        "        print(i)\n",
        "        data=item[\"Table\"]\n",
        "\n",
        "        df=list_to_df(data)\n",
        "        \n",
        "        print(type(df) == pd.DataFrame)\n",
        "        agent = create_csv_agent(\n",
        "        ChatOpenAI(temperature=0.3, model=\"gpt-3.5-turbo\"),\n",
        "        path=None,\n",
        "        pddf=df,\n",
        "        verbose=True,\n",
        "        agent_type=AgentType.OPENAI_FUNCTIONS\n",
        "        )\n",
        "        num_tries = 5\n",
        "        for try_ in range(0,num_tries):\n",
        "            try:\n",
        "                a=agent.run(item[\"Question\"])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                print(\"failed, but we can try %d more time(s)\" % (num_tries - try_ - 1))\n",
        "                if try_ == num_tries-2:\n",
        "                    a = 1\n",
        "            else:\n",
        "                #print(\"YESS!!! Success...\")\n",
        "                break\n",
        "        # try:\n",
        "            \n",
        "        # except Exception as e:\n",
        "        #     print(e)\n",
        "        item[\"LC_agent_res\"]=a\n",
        "        ans=item [\"gdres\"]\n",
        "        print(a,ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('gpt_eval_agents.json', 'r') as f:\n",
        "    gpt_eval=json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(gpt_eval),gpt_eval[900].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for item in gpt_eval:\n",
        "    if \"LC_agent_res\" in item and item[\"LC_agent_res\"].startswith(\"It seems that there is\"):\n",
        "        print(item[\"LC_agent_res\"])\n",
        "        del item[\"LC_agent_res\"]\n",
        "        #print(\"ok\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%store gpt_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%store -r gpt_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open (\"gpt_eval_agents_res.json\",\"w\") as f:\n",
        "    json.dump(gpt_eval,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt_eval[0][\"Question\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent = create_csv_agent(\n",
        "    OpenAI(temperature=0.7),\n",
        "    file_path ,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        ")\n",
        "b=agent.run(\"Which team has an unknown coach and location of Athelstone?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = CSVLoader(file_path=\"./example_data/mlb_teams_2012.csv\", source_column=\"Team\")\n",
        "\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent = create_csv_agent(\n",
        "    OpenAI(temperature=0.7),\n",
        "    \"titanic.csv\",\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "agent.run(\"how many rows are there?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = CSVLoader(file_path=\"./example_data/mlb_teams_2012.csv\", source_column=\"Team\")\n",
        "\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQMfek7xfk1W"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_formular(question: str,table, model='gpt-3.5-turbo'):\n",
        "    llm = ChatOpenAI(model_name=model, max_tokens=50,)\n",
        "    prompt = \"Write a excel formula to answer the quesion based on table beleow\\n\"\\\n",
        "        \"You can use functions like SUM,XLOOKUP,UNIQUE,AVERAGE,etc...\\n\"\\\n",
        "             \"{question}\\n\" \\\n",
        "             \"Here is the table: {table}.\\n\" \\\n",
        "             \"{format_instructions}\"\n",
        "             \n",
        "    prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "    \n",
        "    #options = ResponseSchema(name=\"words\", description=\"The words are related to bad behavior.\")\n",
        "    options = ResponseSchema(name=\"Formula\", description=\"The formula is related to question\")\n",
        "    response_schemas = [options]\n",
        "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "    form_instructions = output_parser.get_format_instructions()\n",
        "    \n",
        "    final_prompt = prompt_template.format_messages(question=question, table=table, format_instructions=form_instructions)\n",
        "    print(final_prompt)\n",
        "    output = llm(final_prompt)\n",
        "    return output_parser.parse(output.content)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(gpt_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ20_OM9fyLa",
        "outputId": "5bce1b52-9651-417c-c6d4-34c07c479c3a"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def list_to_csv(data, file_path):\n",
        "    with open(file_path, 'w', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerows(data)\n",
        "\n",
        "\n",
        "file_path = 'output.csv'\n",
        "# Pass a query to the data\n",
        "for i,item in enumerate(gpt_eval):\n",
        "    if \"LC_res\" not in item.keys():\n",
        "        print(i)\n",
        "        data=item[\"Table\"]\n",
        "\n",
        "        list_to_csv(data, file_path)\n",
        "        #print(\"CSV file successfully created.\")\n",
        "\n",
        "        loader = CSVLoader(file_path=file_path)  \n",
        "\n",
        "        # Create an index using the loaded documents\n",
        "        index_creator = VectorstoreIndexCreator()\n",
        "        docsearch = index_creator.from_loaders([loader])\n",
        "        # Create a question-answering chain using the index\n",
        "        chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
        "        query=item [\"Question\"]\n",
        "        print(query)\n",
        "        response = chain({\"question\": query})\n",
        "        item[\"LC_res\"]=response['result']\n",
        "        ans=item [\"gdres\"]\n",
        "        print(response['result'],ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for item in gpt_eval[:1]:\n",
        "    a=str(item [\"gdres\"])\n",
        "    b=str(item[\"LC_res\"][\"result\"])\n",
        "    if(a.lower()!=b.lower()):\n",
        "    #if(1):\n",
        "        print(a,b)\n",
        "    else:\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from thefuzz import fuzz\n",
        "from thefuzz import process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fuzzy_cmp_str(a:str,b:str):\n",
        "    a,b=str(a).lower(),str(b).lower()\n",
        "    return fuzz.partial_ratio(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "thres=95\n",
        "count=0\n",
        "for i in range(len(gpt_eval)):\n",
        "    radio=fuzzy_cmp_str(gpt_eval[i][\"LC_res\"],gpt_eval[i][\"gdres\"])\n",
        "    #print(radio)\n",
        "    if(radio>thres):\n",
        "        count+=1\n",
        "        print(gpt_eval[i][\"LC_res\"],\"||\",gpt_eval[i][\"gdres\"])\n",
        "print(count/len(gpt_eval))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
