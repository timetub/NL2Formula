{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RKaXSkJcwxB",
        "outputId": "099c945b-1469-4c2c-f23d-313cd38014b0"
      },
      "outputs": [],
      "source": [
        "import xlwings as xw\n",
        "from xlwings import view\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxLWAbONc3ea"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "import pandas as pd\n",
        "import os,read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib,utils,json,os\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import importlib,utils,json,os\n",
        "from utils import *\n",
        "gpt_eval=utils.read_json(\"gpt_eval_3000.json\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = read.read_json(os.path.join('configuration.json'))['OpenAI_api_key']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQMfek7xfk1W"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_formular(question: str,table, model='gpt-3.5-turbo'):\n",
        "    llm = ChatOpenAI(model_name=model, max_tokens=50,)\n",
        "    prompt = \"Write a excel formula to answer the quesion based on table beleow\\n\"\\\n",
        "        \"You can use functions like SUM,XLOOKUP,UNIQUE,AVERAGE,etc...\\n\"\\\n",
        "             \"{question}\\n\" \\\n",
        "             \"Here is the table: {table}.\\n\" \\\n",
        "             \"{format_instructions}\"\n",
        "             \n",
        "    prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "    options = ResponseSchema(name=\"Formula\", description=\"The formula is related to question\")\n",
        "    response_schemas = [options]\n",
        "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "    form_instructions = output_parser.get_format_instructions()\n",
        "    \n",
        "    final_prompt = prompt_template.format_messages(question=question, table=table, format_instructions=form_instructions)\n",
        "    print(final_prompt)\n",
        "    output = llm(final_prompt)\n",
        "    return output_parser.parse(output.content)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt_eval=utils.read_json(\"gpt_eval_direct.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt_eval[1].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ20_OM9fyLa",
        "outputId": "5bce1b52-9651-417c-c6d4-34c07c479c3a"
      },
      "outputs": [],
      "source": [
        "import csv,io\n",
        "\n",
        "def list_to_csv(data, file_path):\n",
        "    with open(file_path, 'w', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerows(data)\n",
        "\n",
        "\n",
        "file_path_f = 'output{i}.csv'\n",
        "# Pass a query to the data\n",
        "for i,item in enumerate(gpt_eval):\n",
        "    if col_name not in item.keys():\n",
        "        print(i)\n",
        "        file_path = file_path_f.format(i=i)\n",
        "        data=item[\"Table\"]\n",
        "\n",
        "        list_to_csv(data, file_path)\n",
        "\n",
        "        loader = CSVLoader(file_path)  # Pass the in-memory file-like object\n",
        "\n",
        "\n",
        "        # Create an index using the loaded documents\n",
        "        index_creator = VectorstoreIndexCreator()\n",
        "        docsearch = index_creator.from_loaders([loader])\n",
        "        # Create a question-answering chain using the index\n",
        "        chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
        "        query=item [\"Question\"]\n",
        "        print(query)\n",
        "        response = chain({\"question\": query})\n",
        "        item[col_name]=response['result']\n",
        "        ans=item [\"gdres\"]\n",
        "        print(response['result'],ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def process_item(i, item):\n",
        "    try:\n",
        "        if col_name not in item.keys():\n",
        "            file_path = file_path_f.format(i=i)\n",
        "            data = item[\"Table\"]\n",
        "\n",
        "            list_to_csv(data, file_path)\n",
        "\n",
        "            loader = CSVLoader(file_path) \n",
        "\n",
        "            index_creator = VectorstoreIndexCreator()\n",
        "            docsearch = index_creator.from_loaders([loader])\n",
        "            chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
        "            query = item[\"Question\"]\n",
        "            response = chain({\"question\": query})\n",
        "            item[col_name]=response['result']\n",
        "            ans = item[\"gdres\"]\n",
        "            print(response['result'],ans)\n",
        "        return item\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing item {i}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Define the number of worker processes to use\n",
        "num_workers = 4\n",
        "\n",
        "# Create a ProcessPoolExecutor\n",
        "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
        "    gpt_eval = list(executor.map(process_item, range(len(gpt_eval)), gpt_eval))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('gpt_eval_direct.json', 'r') as f:\n",
        "    res_list=json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('gpt_eval_agents.json', 'r') as f:\n",
        "    res_list=json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from thefuzz import fuzz\n",
        "from thefuzz import process\n",
        "\n",
        "def fuzzy_cmp_str(a:str,b:str):\n",
        "    a,b=str(a).lower(),str(b).lower()\n",
        "    return fuzz.partial_ratio(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "thres=95\n",
        "count=0\n",
        "col_name=\"LC_agent_res\"\n",
        "col_name=\"LC_res\"\n",
        "\n",
        "for i,item in enumerate(res_list):\n",
        "    \n",
        "    item['res']=\"failed\"\n",
        "    radio=fuzzy_cmp_str(res_list[i][col_name],res_list[i][\"gdres\"])\n",
        "    #print(radio)\n",
        "    if(radio>thres):\n",
        "        count+=1\n",
        "        item['res']=\"exe_match\"\n",
        "        print(res_list[i][col_name],\"||\",res_list[i][\"gdres\"])\n",
        "    else:\n",
        "        item['res']=\"failed\"\n",
        "print(count/len(res_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "thres=95\n",
        "count=0\n",
        "col_name=\"LC_agent_res\"\n",
        "col_name=\"llm\"\n",
        "\n",
        "for i,item in enumerate(res_list):\n",
        "    \n",
        "    item['res']=\"failed\"\n",
        "    radio=fuzzy_cmp_str(res_list[i][col_name],res_list[i][\"gdres\"])\n",
        "    #print(radio)\n",
        "    if(radio>thres):\n",
        "        count+=1\n",
        "        item['res']=\"exe_match\"\n",
        "        print(res_list[i][col_name],\"||\",res_list[i][\"gdres\"])\n",
        "    else:\n",
        "        item['res']=\"failed\"\n",
        "print(count/len(res_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAeDtDbmoT9C"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 初始化计数器\n",
        "counters = {\n",
        "    'easy': {'success': 0, 'failed': 0},\n",
        "    'medium': {'success': 0, 'failed': 0},\n",
        "    'hard': {'success': 0, 'failed': 0},\n",
        "    'Calculation': {'success': 0, 'failed': 0},\n",
        "}\n",
        "\n",
        "# 统计计数\n",
        "for item in res_list:\n",
        "    level = item['Level']\n",
        "    result = item['res']\n",
        "    if result == 'exact_match' or result == 'exe_match':\n",
        "        counters[level]['success'] += 1\n",
        "    elif result == 'failed':\n",
        "        counters[level]['failed'] += 1\n",
        "\n",
        "# 打印结果\n",
        "for level, results in counters.items():\n",
        "    print(f\"Level: {level}\")\n",
        "    total = sum(results.values())\n",
        "    for result, count in results.items():\n",
        "        percentage = (count / total) * 100\n",
        "        print(f\"{result}: {count} ({percentage:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_res=pd.DataFrame(counters).T\n",
        "df_res[\"rate\"]=df_res['success']/(df_res['success']+df_res[\"failed\"])\n",
        "df_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_res['success'].sum()/(df_res['success'].sum()+df_res['failed'].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
